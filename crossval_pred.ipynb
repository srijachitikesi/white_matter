{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cust_dataset import CustDataset\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing CustomDataset 1\n",
      "Number of rows selected: 100\n",
      "Loaded labels...\n",
      "sss done\n",
      "CustomDataset initialized.\n"
     ]
    }
   ],
   "source": [
    "data = CustDataset(transform = \n",
    "                        transforms.Compose([\n",
    "                            transforms.RandomHorizontalFlip()\n",
    "                            ]),train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src_subject_id\n",
       "NDARINV005V6D2C    0.216762\n",
       "NDARINV007W6H7B    0.664711\n",
       "NDARINV00CY2MDM    0.633248\n",
       "NDARINV00HEV6HB    0.571336\n",
       "NDARINV00LJVZK2    0.571497\n",
       "                     ...   \n",
       "NDARINV0BVP2PTD    0.385129\n",
       "NDARINV0BXXNBH4    0.582933\n",
       "NDARINV0C471G23    0.485788\n",
       "NDARINV0C765WK4    0.390668\n",
       "NDARINV0CBFTKR7    0.823856\n",
       "Name: tfmri_nb_all_beh_ctotal_mrt_normalised, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vars['tfmri_nb_all_beh_ctotal_mrt_normalised']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing CustomDataset 1\n",
      "Number of rows selected: 200\n",
      "Loaded labels...\n",
      "sss done\n",
      "CustomDataset initialized.\n",
      "Initializing CustomDataset 1\n",
      "Number of rows selected: 200\n",
      "Loaded labels...\n",
      "sss done\n",
      "CustomDataset initialized.\n",
      "Initializing CustomDataset 1\n",
      "Number of rows selected: 200\n",
      "Loaded labels...\n",
      "sss done\n",
      "CustomDataset initialized.\n"
     ]
    }
   ],
   "source": [
    "train_data = CustDataset(transform = \n",
    "                        transforms.Compose([\n",
    "                            transforms.RandomHorizontalFlip()\n",
    "                            ]),train=True)\n",
    "test_data = CustDataset(train=False,valid=False)\n",
    "# print(len(test_data.test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_data.train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_data.test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21676181 0.66471115 0.63324766 0.5713358  0.57149662 0.7577393\n",
      " 0.57232634 0.61050847 0.47869976 0.51985101 0.53997735 0.37059094\n",
      " 0.60708203 0.66142549 0.6729254  0.35087163 0.58665731 0.62656841\n",
      " 0.66991805 0.46521512 0.53951311 0.49214146 0.50427442 0.47868265\n",
      " 0.91581694 0.42208784 0.43668389 0.32992534 0.59487053 0.5282757\n",
      " 0.44143295 0.50994597 0.6116105  0.51132372 0.48236061 0.61028327\n",
      " 0.59409205 0.76070599 0.43415927 0.56169644 0.53289207 0.62896537\n",
      " 0.37479436 0.47714711 0.45236903 0.44394289 0.30892307 0.5700276\n",
      " 0.28259998 0.58507525 0.5021404  0.58850934 0.5238485  0.30032808\n",
      " 0.59128386 0.41683087 0.50407409 0.40730873 0.39579211 0.83310705\n",
      " 0.45373871 0.6144514  0.4811114  0.34226829 0.38972743 0.54549302\n",
      " 0.56584067 0.61209719 0.50058417 0.54000593 0.5537693  0.47706506\n",
      " 0.43992347 0.51654233 0.4525863  0.38823965 0.45403081 0.48694961\n",
      " 0.5019324  0.48281998 0.52053188 0.37912244 0.5531325  0.58137635\n",
      " 0.36515862 0.4658948  0.3813442  0.58295918 0.53155548 0.4843096\n",
      " 0.3616363  0.54164859 0.50613898 0.4070128  0.68081883 0.38512906\n",
      " 0.58293269 0.48578756 0.39066795 0.82385595 0.54635581 0.34260156\n",
      " 0.52455658 0.65171322 0.59904348 0.48912033 0.52765371 0.82913328\n",
      " 0.46685029 0.64497249 0.43103472 0.5690722  0.50323086 0.74945384\n",
      " 0.47696316 0.57021342 0.46461696 0.56011555 0.46304517 0.64493925\n",
      " 0.55202339 0.39247041 0.52402584 0.50226503 0.4463171  0.45192965\n",
      " 0.44420642 0.48131518 0.4763928  0.56821437 0.46055683 0.37079835\n",
      " 0.83844846 0.44871923 0.45658117 0.43093098 0.42044654 0.49775697\n",
      " 0.50157502 0.49261629 0.41822178 0.67872813 0.51335294 0.49380547\n",
      " 0.54674006 0.44133194 0.56097149 0.50253388 0.54264433 0.48282801\n",
      " 0.5434416  0.31675376 0.60439578 0.58793388 0.24313825 0.55119022\n",
      " 0.43007528 0.33652847 0.37780634 0.36481776 0.48526046 0.53282975\n",
      " 0.46552109 0.39707744 0.19686149 0.650545   0.6858477  0.49360449\n",
      " 0.6909695  0.49790809 0.41527481 0.53299438 0.56707653 0.56363124\n",
      " 0.60110445 0.38157817 0.63758102 0.54234988 0.58090079 0.6888945\n",
      " 0.56297852 0.43973382 0.83779713 0.56319465 0.67366654 0.54469526\n",
      " 0.3678446  0.64621145 0.62774596 0.49990792 0.63250374 0.39485431\n",
      " 0.49052949 0.4154048  0.58568237 0.55079611 0.54263004 0.40239951\n",
      " 0.56216609 0.3990301 ]\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data,batch_size=10, \n",
    "                                sampler= train_sampler, num_workers=4)\n",
    "\n",
    "test_loader = DataLoader(test_data,batch_size=10,\n",
    "                                sampler= test_sampler, num_workers=4)\n",
    "# print(valid_data.vars.tfmri_nb_all_beh_ctotal_mrt_normalised.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([10, 182, 218, 182])\n",
      "Shape of y: torch.Size([10]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# device = (\n",
    "#     \"cuda\"\n",
    "#     if torch.cuda.is_available()\n",
    "#     else \"mps\"\n",
    "#     if torch.backends.mps.is_available()\n",
    "#     else \"cpu\"\n",
    "# )\n",
    "# print(f\"Using {device} device\")\n",
    "\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (cv1): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (cv2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (cv3): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (bn3): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (cv4): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (bn4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (cv5): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (bn5): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=1, bias=True)\n",
      "  (d3d): Dropout3d(p=0.2, inplace=False)\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "    (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (convs): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from network import Network\n",
    "\n",
    "model = Network().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader)\n",
    "    print(\"train size\", size)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # with torch.no_grad():\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device).float(), y.to(device).float()\n",
    "        X = torch.unsqueeze(X, 1).float() \n",
    "        pred = model(X)\n",
    "        pred = pred.squeeze()  \n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    avg_train_loss = train_loss / len(dataloader)\n",
    "    print(f\"Average train loss: {avg_train_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader)\n",
    "    print(\"test size\", size)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device).float(), y.to(device).float()\n",
    "            X = torch.unsqueeze(X, 1).float() \n",
    "            pred = model(X)\n",
    "            pred = pred.squeeze()  \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(dataloader)\n",
    "    print(f\"Average test loss: {avg_test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.double().to(device)\n",
    "model = model.float()  # Ensure the model is in float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model, loss_fn):\n",
    "    size = len(dataloader)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            X, y = X.float(), y.float()  \n",
    "            X = torch.unsqueeze(X, 1).float()\n",
    "\n",
    "            pred = model(X)\n",
    "            total_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_loss:>8f} \\n\")\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "train size 16\n",
      "Average train loss: 3.42129001673311\n",
      "test size 4\n",
      "Average test loss: 1.2657445669174194\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "train size 16\n",
      "Average train loss: 0.3663286631926894\n",
      "test size 4\n",
      "Average test loss: 1.2589514255523682\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "train size 16\n",
      "Average train loss: 0.1251244021113962\n",
      "test size 4\n",
      "Average test loss: 0.4760708659887314\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "train size 16\n",
      "Average train loss: 0.13724293652921915\n",
      "test size 4\n",
      "Average test loss: 0.11718388460576534\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "train size 16\n",
      "Average train loss: 0.12132254987955093\n",
      "test size 4\n",
      "Average test loss: 0.0278573390096426\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "X, y = X.to(device).float(), y.to(device).float()\n",
    "X = torch.unsqueeze(X, 1).float() \n",
    "pred = model(X)\n",
    "# pred = pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4604],\n",
       "         [0.4926],\n",
       "         [0.3295],\n",
       "         [0.5661],\n",
       "         [0.5211],\n",
       "         [0.4865],\n",
       "         [0.4909],\n",
       "         [0.3973],\n",
       "         [0.4397],\n",
       "         [0.5174]], grad_fn=<AddmmBackward0>),\n",
       " tensor([0.4891, 0.4828, 0.3971, 0.4204, 0.5913, 0.5021, 0.5512, 0.4463, 0.3882,\n",
       "         0.3791]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/schitikesi1/miniconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(pred, y)\n",
    "# train_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0088, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_loader))\n",
    "X, y = X.to(device).float(), y.to(device).float()\n",
    "X = torch.unsqueeze(X, 1).float() \n",
    "pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3515],\n",
       "         [0.4234],\n",
       "         [0.4239],\n",
       "         [0.3931],\n",
       "         [0.4084],\n",
       "         [0.4451],\n",
       "         [0.4081],\n",
       "         [0.4375],\n",
       "         [0.4330],\n",
       "         [0.2377]], grad_fn=<AddmmBackward0>),\n",
       " tensor([0.5416, 0.3907, 0.4540, 0.3003, 0.4999, 0.4070, 0.6376, 0.5702, 0.5041,\n",
       "         0.4537]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
